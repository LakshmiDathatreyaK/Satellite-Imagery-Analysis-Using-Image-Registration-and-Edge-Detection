{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw0Myshcc4JJ",
        "outputId": "4f495b14-70d3-479d-bfad-d038ff76d1af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BRISK - CANNY"
      ],
      "metadata": {
        "id": "Apv5ThfYfodO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.metrics import structural_similarity as ssim, mean_squared_error as mse\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Load image with OpenCV\n",
        "def load_image_cv(path):\n",
        "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "\n",
        "def process_image_pair(args):\n",
        "    filename_a, filename_b, filename_label = args\n",
        "    img1_path = os.path.join(folder_a_path, filename_a)\n",
        "    img1 = load_image_cv(img1_path)\n",
        "\n",
        "    img2_path = os.path.join(folder_b_path, filename_b)\n",
        "    img2 = load_image_cv(img2_path)\n",
        "\n",
        "    gt_image_path = os.path.join(label_path, filename_label)\n",
        "    gt_image = io.imread(gt_image_path)\n",
        "\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    keypoints1, descriptors1 = brisk.detectAndCompute(img1_gray, None)\n",
        "    keypoints2, descriptors2 = brisk.detectAndCompute(img2_gray, None)\n",
        "\n",
        "    descriptors1_float = descriptors1.astype(np.float32)\n",
        "    descriptors2_float = descriptors2.astype(np.float32)\n",
        "\n",
        "    matches = flann.knnMatch(descriptors1_float, descriptors2_float, k=2)\n",
        "\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.85 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    if len(good_matches) > 10:\n",
        "        points1 = np.zeros((len(good_matches), 2), dtype=np.float32)\n",
        "        points2 = np.zeros_like(points1)\n",
        "\n",
        "        for i, match in enumerate(good_matches):\n",
        "            points1[i, :] = keypoints1[match.queryIdx].pt\n",
        "            points2[i, :] = keypoints2[match.trainIdx].pt\n",
        "\n",
        "        M, mask = cv2.estimateAffinePartial2D(points1, points2, method=cv2.RANSAC)\n",
        "\n",
        "        registered_img = cv2.warpAffine(img2, M, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "        registered_img_gray = cv2.cvtColor(registered_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        edges = cv2.Canny(registered_img_gray, 200, 585)\n",
        "        edges_binary = (edges > np.percentile(edges, 90)).astype(np.uint8)\n",
        "\n",
        "        kernel = np.ones((5, 5), np.uint8)\n",
        "        dilated_edges = cv2.dilate(edges, kernel, iterations=1)\n",
        "\n",
        "        binary_change_map = dilated_edges > 0\n",
        "\n",
        "        ssim_index = ssim(registered_img_gray, gt_image)\n",
        "        mse_value = mse(registered_img_gray, gt_image)\n",
        "\n",
        "        return ssim_index, mse_value\n",
        "\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/data/train'\n",
        "folder_a_path = os.path.join(base_dir, 'A')\n",
        "folder_b_path = os.path.join(base_dir, 'B')\n",
        "label_path = os.path.join(base_dir, 'label')\n",
        "\n",
        "folder_a_images = os.listdir(folder_a_path)\n",
        "folder_b_images = os.listdir(folder_b_path)\n",
        "label_images = os.listdir(label_path)\n",
        "\n",
        "brisk = cv2.BRISK_create()\n",
        "\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=3)\n",
        "search_params = dict(checks=70)\n",
        "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "ssim_scores = []\n",
        "mse_scores = []\n",
        "\n",
        "# Create pool for multiprocessing\n",
        "pool = Pool()\n",
        "\n",
        "# Iterate through each image pair\n",
        "for ssim_score, mse_score in pool.imap_unordered(process_image_pair, zip(folder_a_images, folder_b_images, label_images)):\n",
        "    if ssim_score is not None:\n",
        "        ssim_scores.append(ssim_score)\n",
        "        mse_scores.append(mse_score)\n",
        "    else:\n",
        "        print(\"Not enough matches for an image pair.\")\n",
        "\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "mean_ssim = np.mean(ssim_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "\n",
        "print(f\"Mean SSIM score: {mean_ssim}\")\n",
        "print(f\"Mean MSE score: {mean_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eABfabN6xPE3",
        "outputId": "92583771-f755-4941-d520-5359b1d03810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean SSIM score: 0.561227233190889\n",
            "Mean MSE score: 5732.9314264511795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BRISK - SOBEL"
      ],
      "metadata": {
        "id": "1LNxsNkhfsby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.metrics import structural_similarity as ssim, mean_squared_error as mse\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Load image with OpenCV\n",
        "def load_image_cv(path):\n",
        "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "\n",
        "def process_image_pair(args):\n",
        "    filename_a, filename_b, filename_label = args\n",
        "    img1_path = os.path.join(folder_a_path, filename_a)\n",
        "    img1 = load_image_cv(img1_path)\n",
        "\n",
        "    img2_path = os.path.join(folder_b_path, filename_b)\n",
        "    img2 = load_image_cv(img2_path)\n",
        "\n",
        "    gt_image_path = os.path.join(label_path, filename_label)\n",
        "    gt_image = io.imread(gt_image_path)\n",
        "\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    keypoints1, descriptors1 = brisk.detectAndCompute(img1_gray, None)\n",
        "    keypoints2, descriptors2 = brisk.detectAndCompute(img2_gray, None)\n",
        "\n",
        "    descriptors1_float = descriptors1.astype(np.float32)\n",
        "    descriptors2_float = descriptors2.astype(np.float32)\n",
        "\n",
        "    matches = flann.knnMatch(descriptors1_float, descriptors2_float, k=2)\n",
        "\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.85 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    if len(good_matches) > 10:\n",
        "        points1 = np.zeros((len(good_matches), 2), dtype=np.float32)\n",
        "        points2 = np.zeros_like(points1)\n",
        "\n",
        "        for i, match in enumerate(good_matches):\n",
        "            points1[i, :] = keypoints1[match.queryIdx].pt\n",
        "            points2[i, :] = keypoints2[match.trainIdx].pt\n",
        "\n",
        "        M, mask = cv2.estimateAffinePartial2D(points1, points2, method=cv2.RANSAC)\n",
        "\n",
        "        registered_img = cv2.warpAffine(img2, M, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "        registered_img_gray = cv2.cvtColor(registered_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Use Sobel operator for edge detection\n",
        "        sobel_x = cv2.Sobel(registered_img_gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "        sobel_y = cv2.Sobel(registered_img_gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "        edges = np.sqrt(sobel_x**2 + sobel_y**2)\n",
        "        edges_binary = (edges > np.percentile(edges, 90)).astype(np.uint8)\n",
        "\n",
        "        kernel = np.ones((5, 5), np.uint8)\n",
        "        dilated_edges = cv2.dilate(edges_binary, kernel, iterations=1)\n",
        "\n",
        "        binary_change_map = dilated_edges > 0\n",
        "\n",
        "        ssim_index = ssim(registered_img_gray, gt_image)\n",
        "        mse_value = mse(registered_img_gray, gt_image)\n",
        "\n",
        "        return ssim_index, mse_value\n",
        "\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/data/train'\n",
        "folder_a_path = os.path.join(base_dir, 'A')\n",
        "folder_b_path = os.path.join(base_dir, 'B')\n",
        "label_path = os.path.join(base_dir, 'label')\n",
        "\n",
        "folder_a_images = os.listdir(folder_a_path)\n",
        "folder_b_images = os.listdir(folder_b_path)\n",
        "label_images = os.listdir(label_path)\n",
        "\n",
        "brisk = cv2.BRISK_create()\n",
        "\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=3)\n",
        "search_params = dict(checks=70)\n",
        "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "ssim_scores = []\n",
        "mse_scores = []\n",
        "\n",
        "# Create pool for multiprocessing\n",
        "pool = Pool()\n",
        "\n",
        "# Iterate through each image pair\n",
        "for ssim_score, mse_score in pool.imap_unordered(process_image_pair, zip(folder_a_images, folder_b_images, label_images)):\n",
        "    if ssim_score is not None:\n",
        "        ssim_scores.append(ssim_score)\n",
        "        mse_scores.append(mse_score)\n",
        "    else:\n",
        "        print(\"Not enough matches for an image pair.\")\n",
        "\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "mean_ssim = np.mean(ssim_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "\n",
        "print(f\"Mean SSIM score: {mean_ssim}\")\n",
        "print(f\"Mean MSE score: {mean_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZnPiTH17c6v",
        "outputId": "13fc0c2d-7498-4d53-937f-b1ca18170e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean SSIM score: 0.5895145157485331\n",
            "Mean MSE score: 5374.1904741458675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BRISK - PREWITT"
      ],
      "metadata": {
        "id": "RSjTf5kufwdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.metrics import structural_similarity as ssim, mean_squared_error as mse\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Load image with OpenCV\n",
        "def load_image_cv(path):\n",
        "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "\n",
        "def process_image_pair(args):\n",
        "    filename_a, filename_b, filename_label = args\n",
        "    img1_path = os.path.join(folder_a_path, filename_a)\n",
        "    img1 = load_image_cv(img1_path)\n",
        "\n",
        "    img2_path = os.path.join(folder_b_path, filename_b)\n",
        "    img2 = load_image_cv(img2_path)\n",
        "\n",
        "    gt_image_path = os.path.join(label_path, filename_label)\n",
        "    gt_image = io.imread(gt_image_path)\n",
        "\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    keypoints1, descriptors1 = brisk.detectAndCompute(img1_gray, None)\n",
        "    keypoints2, descriptors2 = brisk.detectAndCompute(img2_gray, None)\n",
        "\n",
        "    descriptors1_float = descriptors1.astype(np.float32)\n",
        "    descriptors2_float = descriptors2.astype(np.float32)\n",
        "\n",
        "    matches = flann.knnMatch(descriptors1_float, descriptors2_float, k=2)\n",
        "\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.85 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    if len(good_matches) > 10:\n",
        "        points1 = np.zeros((len(good_matches), 2), dtype=np.float32)\n",
        "        points2 = np.zeros_like(points1)\n",
        "\n",
        "        for i, match in enumerate(good_matches):\n",
        "            points1[i, :] = keypoints1[match.queryIdx].pt\n",
        "            points2[i, :] = keypoints2[match.trainIdx].pt\n",
        "\n",
        "        M, mask = cv2.estimateAffinePartial2D(points1, points2, method=cv2.RANSAC)\n",
        "\n",
        "        registered_img = cv2.warpAffine(img2, M, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "        registered_img_gray = cv2.cvtColor(registered_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Use Prewitt operator for edge detection\n",
        "        prewitt_x = cv2.Sobel(registered_img_gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "        prewitt_y = cv2.Sobel(registered_img_gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "        edges = np.sqrt(prewitt_x**2 + prewitt_y**2)\n",
        "        edges_binary = (edges > np.percentile(edges, 90)).astype(np.uint8)\n",
        "\n",
        "        kernel = np.ones((5, 5), np.uint8)\n",
        "        dilated_edges = cv2.dilate(edges_binary, kernel, iterations=1)\n",
        "\n",
        "        binary_change_map = dilated_edges > 0\n",
        "\n",
        "        ssim_index = ssim(registered_img_gray, gt_image)\n",
        "        mse_value = mse(registered_img_gray, gt_image)\n",
        "\n",
        "        return ssim_index, mse_value\n",
        "\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/data/train'\n",
        "folder_a_path = os.path.join(base_dir, 'A')\n",
        "folder_b_path = os.path.join(base_dir, 'B')\n",
        "label_path = os.path.join(base_dir, 'label')\n",
        "\n",
        "folder_a_images = os.listdir(folder_a_path)\n",
        "folder_b_images = os.listdir(folder_b_path)\n",
        "label_images = os.listdir(label_path)\n",
        "\n",
        "brisk = cv2.BRISK_create()\n",
        "\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=3)\n",
        "search_params = dict(checks=70)\n",
        "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "ssim_scores = []\n",
        "mse_scores = []\n",
        "\n",
        "# Create pool for multiprocessing\n",
        "pool = Pool()\n",
        "\n",
        "# Iterate through each image pair\n",
        "for ssim_score, mse_score in pool.imap_unordered(process_image_pair, zip(folder_a_images, folder_b_images, label_images)):\n",
        "    if ssim_score is not None:\n",
        "        ssim_scores.append(ssim_score)\n",
        "        mse_scores.append(mse_score)\n",
        "    else:\n",
        "        print(\"Not enough matches for an image pair.\")\n",
        "\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "mean_ssim = np.mean(ssim_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "\n",
        "print(f\"Mean SSIM score: {mean_ssim}\")\n",
        "print(f\"Mean MSE score: {mean_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0eglMj0dUgH",
        "outputId": "2a82b7cb-d561-43e4-e4ae-769c3c2ed628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean SSIM score: 0.5761191611681542\n",
            "Mean MSE score: 5623.25329404038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BRISK - LOG"
      ],
      "metadata": {
        "id": "XCvvzFfbf0m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.metrics import structural_similarity as ssim, mean_squared_error as mse\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Load image with OpenCV\n",
        "def load_image_cv(path):\n",
        "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "\n",
        "def process_image_pair(args):\n",
        "    filename_a, filename_b, filename_label = args\n",
        "    img1_path = os.path.join(folder_a_path, filename_a)\n",
        "    img1 = load_image_cv(img1_path)\n",
        "\n",
        "    img2_path = os.path.join(folder_b_path, filename_b)\n",
        "    img2 = load_image_cv(img2_path)\n",
        "\n",
        "    gt_image_path = os.path.join(label_path, filename_label)\n",
        "    gt_image = io.imread(gt_image_path)\n",
        "\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    keypoints1, descriptors1 = brisk.detectAndCompute(img1_gray, None)\n",
        "    keypoints2, descriptors2 = brisk.detectAndCompute(img2_gray, None)\n",
        "\n",
        "    descriptors1_float = descriptors1.astype(np.float32)\n",
        "    descriptors2_float = descriptors2.astype(np.float32)\n",
        "\n",
        "    matches = flann.knnMatch(descriptors1_float, descriptors2_float, k=2)\n",
        "\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.85 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    if len(good_matches) > 10:\n",
        "        points1 = np.zeros((len(good_matches), 2), dtype=np.float32)\n",
        "        points2 = np.zeros_like(points1)\n",
        "\n",
        "        for i, match in enumerate(good_matches):\n",
        "            points1[i, :] = keypoints1[match.queryIdx].pt\n",
        "            points2[i, :] = keypoints2[match.trainIdx].pt\n",
        "\n",
        "        M, mask = cv2.estimateAffinePartial2D(points1, points2, method=cv2.RANSAC)\n",
        "\n",
        "        registered_img = cv2.warpAffine(img2, M, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "        registered_img_gray = cv2.cvtColor(registered_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Use Laplacian of Gaussian (LOG) operator for edge detection\n",
        "        edges = cv2.Laplacian(registered_img_gray, cv2.CV_64F)\n",
        "        edges_binary = (edges > np.percentile(edges, 90)).astype(np.uint8)\n",
        "\n",
        "        kernel = np.ones((5, 5), np.uint8)\n",
        "        dilated_edges = cv2.dilate(edges_binary, kernel, iterations=1)\n",
        "\n",
        "        binary_change_map = dilated_edges > 0\n",
        "\n",
        "        ssim_index = ssim(registered_img_gray, gt_image)\n",
        "        mse_value = mse(registered_img_gray, gt_image)\n",
        "\n",
        "        return ssim_index, mse_value\n",
        "\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/data/train'\n",
        "folder_a_path = os.path.join(base_dir, 'A')\n",
        "folder_b_path = os.path.join(base_dir, 'B')\n",
        "label_path = os.path.join(base_dir, 'label')\n",
        "\n",
        "folder_a_images = os.listdir(folder_a_path)\n",
        "folder_b_images = os.listdir(folder_b_path)\n",
        "label_images = os.listdir(label_path)\n",
        "\n",
        "brisk = cv2.BRISK_create()\n",
        "\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=3)\n",
        "search_params = dict(checks=70)\n",
        "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "ssim_scores = []\n",
        "mse_scores = []\n",
        "\n",
        "# Create pool for multiprocessing\n",
        "pool = Pool()\n",
        "\n",
        "# Iterate through each image pair\n",
        "for ssim_score, mse_score in pool.imap_unordered(process_image_pair, zip(folder_a_images, folder_b_images, label_images)):\n",
        "    if ssim_score is not None:\n",
        "        ssim_scores.append(ssim_score)\n",
        "        mse_scores.append(mse_score)\n",
        "    else:\n",
        "        print(\"Not enough matches for an image pair.\")\n",
        "\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "mean_ssim = np.mean(ssim_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "\n",
        "print(f\"Mean SSIM score: {mean_ssim}\")\n",
        "print(f\"Mean MSE score: {mean_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrI_w0AadhiU",
        "outputId": "380cfda3-06cc-4bcd-ec67-1bdc5c95af03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean SSIM score: 0.5829774264858655\n",
            "Mean MSE score: 5493.61226380809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BRISK - SCHAAR"
      ],
      "metadata": {
        "id": "6uNiovwFf3Pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.metrics import structural_similarity as ssim, mean_squared_error as mse\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Load image with OpenCV\n",
        "def load_image_cv(path):\n",
        "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "\n",
        "def process_image_pair(args):\n",
        "    filename_a, filename_b, filename_label = args\n",
        "    img1_path = os.path.join(folder_a_path, filename_a)\n",
        "    img1 = load_image_cv(img1_path)\n",
        "\n",
        "    img2_path = os.path.join(folder_b_path, filename_b)\n",
        "    img2 = load_image_cv(img2_path)\n",
        "\n",
        "    gt_image_path = os.path.join(label_path, filename_label)\n",
        "    gt_image = io.imread(gt_image_path)\n",
        "\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    keypoints1, descriptors1 = brisk.detectAndCompute(img1_gray, None)\n",
        "    keypoints2, descriptors2 = brisk.detectAndCompute(img2_gray, None)\n",
        "\n",
        "    descriptors1_float = descriptors1.astype(np.float32)\n",
        "    descriptors2_float = descriptors2.astype(np.float32)\n",
        "\n",
        "    matches = flann.knnMatch(descriptors1_float, descriptors2_float, k=2)\n",
        "\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.85 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    if len(good_matches) > 10:\n",
        "        points1 = np.zeros((len(good_matches), 2), dtype=np.float32)\n",
        "        points2 = np.zeros_like(points1)\n",
        "\n",
        "        for i, match in enumerate(good_matches):\n",
        "            points1[i, :] = keypoints1[match.queryIdx].pt\n",
        "            points2[i, :] = keypoints2[match.trainIdx].pt\n",
        "\n",
        "        M, mask = cv2.estimateAffinePartial2D(points1, points2, method=cv2.RANSAC)\n",
        "\n",
        "        registered_img = cv2.warpAffine(img2, M, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "        registered_img_gray = cv2.cvtColor(registered_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Use Scharr operator for edge detection\n",
        "        scharr_x = cv2.Scharr(registered_img_gray, cv2.CV_64F, 1, 0)\n",
        "        scharr_y = cv2.Scharr(registered_img_gray, cv2.CV_64F, 0, 1)\n",
        "        edges = np.sqrt(scharr_x**2 + scharr_y**2)\n",
        "        edges_binary = (edges > np.percentile(edges, 90)).astype(np.uint8)\n",
        "\n",
        "        kernel = np.ones((5, 5), np.uint8)\n",
        "        dilated_edges = cv2.dilate(edges_binary, kernel, iterations=1)\n",
        "\n",
        "        binary_change_map = dilated_edges > 0\n",
        "\n",
        "        ssim_index = ssim(registered_img_gray, gt_image)\n",
        "        mse_value = mse(registered_img_gray, gt_image)\n",
        "\n",
        "        return ssim_index, mse_value\n",
        "\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/data/train'\n",
        "folder_a_path = os.path.join(base_dir, 'A')\n",
        "folder_b_path = os.path.join(base_dir, 'B')\n",
        "label_path = os.path.join(base_dir, 'label')\n",
        "\n",
        "folder_a_images = os.listdir(folder_a_path)\n",
        "folder_b_images = os.listdir(folder_b_path)\n",
        "label_images = os.listdir(label_path)\n",
        "\n",
        "brisk = cv2.BRISK_create()\n",
        "\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=3)\n",
        "search_params = dict(checks=70)\n",
        "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "ssim_scores = []\n",
        "mse_scores = []\n",
        "\n",
        "# Create pool for multiprocessing\n",
        "pool = Pool()\n",
        "\n",
        "# Iterate through each image pair\n",
        "for ssim_score, mse_score in pool.imap_unordered(process_image_pair, zip(folder_a_images, folder_b_images, label_images)):\n",
        "    if ssim_score is not None:\n",
        "        ssim_scores.append(ssim_score)\n",
        "        mse_scores.append(mse_score)\n",
        "    else:\n",
        "        print(\"Not enough matches for an image pair.\")\n",
        "\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "mean_ssim = np.mean(ssim_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "\n",
        "print(f\"Mean SSIM score: {mean_ssim}\")\n",
        "print(f\"Mean MSE score: {mean_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVY_Ma5MdvD2",
        "outputId": "35a7c3b4-4c96-40ae-e018-28f1b0f485ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean SSIM score: 0.5364655800114982\n",
            "Mean MSE score: 5737.0052035149565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ORB - CANNY"
      ],
      "metadata": {
        "id": "QqmhapQzY27f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.metrics import structural_similarity as ssim, mean_squared_error as mse\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Load image with OpenCV\n",
        "def load_image_cv(path):\n",
        "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "\n",
        "def process_image_pair(args):\n",
        "    filename_a, filename_b, filename_label = args\n",
        "    img1_path = os.path.join(folder_a_path, filename_a)\n",
        "    img1 = load_image_cv(img1_path)\n",
        "\n",
        "    img2_path = os.path.join(folder_b_path, filename_b)\n",
        "    img2 = load_image_cv(img2_path)\n",
        "\n",
        "    gt_image_path = os.path.join(label_path, filename_label)\n",
        "    gt_image = io.imread(gt_image_path)\n",
        "\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    orb = cv2.ORB_create()\n",
        "\n",
        "    keypoints1, descriptors1 = orb.detectAndCompute(img1_gray, None)\n",
        "    keypoints2, descriptors2 = orb.detectAndCompute(img2_gray, None)\n",
        "\n",
        "    descriptors1_float = descriptors1.astype(np.float32)\n",
        "    descriptors2_float = descriptors2.astype(np.float32)\n",
        "\n",
        "    matches = flann.knnMatch(descriptors1_float, descriptors2_float, k=2)\n",
        "\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.85 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    if len(good_matches) > 10:\n",
        "        points1 = np.zeros((len(good_matches), 2), dtype=np.float32)\n",
        "        points2 = np.zeros_like(points1)\n",
        "\n",
        "        for i, match in enumerate(good_matches):\n",
        "            points1[i, :] = keypoints1[match.queryIdx].pt\n",
        "            points2[i, :] = keypoints2[match.trainIdx].pt\n",
        "\n",
        "        M, mask = cv2.estimateAffinePartial2D(points1, points2, method=cv2.RANSAC)\n",
        "\n",
        "        registered_img = cv2.warpAffine(img2, M, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "        registered_img_gray = cv2.cvtColor(registered_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        edges = cv2.Canny(registered_img_gray, 200, 585)\n",
        "        edges_binary = (edges > np.percentile(edges, 90)).astype(np.uint8)\n",
        "\n",
        "        kernel = np.ones((5, 5), np.uint8)\n",
        "        dilated_edges = cv2.dilate(edges, kernel, iterations=1)\n",
        "\n",
        "        binary_change_map = dilated_edges > 0\n",
        "\n",
        "        ssim_index = ssim(registered_img_gray, gt_image)\n",
        "        mse_value = mse(registered_img_gray, gt_image)\n",
        "\n",
        "        return ssim_index, mse_value\n",
        "\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/data/train'\n",
        "folder_a_path = os.path.join(base_dir, 'A')\n",
        "folder_b_path = os.path.join(base_dir, 'B')\n",
        "label_path = os.path.join(base_dir, 'label')\n",
        "\n",
        "folder_a_images = os.listdir(folder_a_path)\n",
        "folder_b_images = os.listdir(folder_b_path)\n",
        "label_images = os.listdir(label_path)\n",
        "\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=3)\n",
        "search_params = dict(checks=70)\n",
        "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "ssim_scores = []\n",
        "mse_scores = []\n",
        "\n",
        "# Create pool for multiprocessing\n",
        "pool = Pool()\n",
        "\n",
        "# Iterate through each image pair\n",
        "for ssim_score, mse_score in pool.imap_unordered(process_image_pair, zip(folder_a_images, folder_b_images, label_images)):\n",
        "    if ssim_score is not None:\n",
        "        ssim_scores.append(ssim_score)\n",
        "        mse_scores.append(mse_score)\n",
        "    else:\n",
        "        print(\"Not enough matches for an image pair.\")\n",
        "\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "mean_ssim = np.mean(ssim_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "\n",
        "print(f\"Mean SSIM score: {mean_ssim}\")\n",
        "print(f\"Mean MSE score: {mean_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AwBAQqOJJAE",
        "outputId": "828742bc-ead7-4b90-d5c6-e859930b4d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean SSIM score: 0.6638272652354902\n",
            "Mean MSE score: 4790.527142421851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ORB - SOBEL"
      ],
      "metadata": {
        "id": "ri4p4_QBY6sH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.metrics import structural_similarity as ssim, mean_squared_error as mse\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Load image with OpenCV\n",
        "def load_image_cv(path):\n",
        "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "\n",
        "def process_image_pair(args):\n",
        "    filename_a, filename_b, filename_label = args\n",
        "    img1_path = os.path.join(folder_a_path, filename_a)\n",
        "    img1 = load_image_cv(img1_path)\n",
        "\n",
        "    img2_path = os.path.join(folder_b_path, filename_b)\n",
        "    img2 = load_image_cv(img2_path)\n",
        "\n",
        "    gt_image_path = os.path.join(label_path, filename_label)\n",
        "    gt_image = io.imread(gt_image_path)\n",
        "\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    orb = cv2.ORB_create()\n",
        "\n",
        "    keypoints1, descriptors1 = orb.detectAndCompute(img1_gray, None)\n",
        "    keypoints2, descriptors2 = orb.detectAndCompute(img2_gray, None)\n",
        "\n",
        "    descriptors1_float = descriptors1.astype(np.float32)\n",
        "    descriptors2_float = descriptors2.astype(np.float32)\n",
        "\n",
        "    matches = flann.knnMatch(descriptors1_float, descriptors2_float, k=2)\n",
        "\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.85 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    if len(good_matches) > 10:\n",
        "        points1 = np.zeros((len(good_matches), 2), dtype=np.float32)\n",
        "        points2 = np.zeros_like(points1)\n",
        "\n",
        "        for i, match in enumerate(good_matches):\n",
        "            points1[i, :] = keypoints1[match.queryIdx].pt\n",
        "            points2[i, :] = keypoints2[match.trainIdx].pt\n",
        "\n",
        "        M, mask = cv2.estimateAffinePartial2D(points1, points2, method=cv2.RANSAC)\n",
        "\n",
        "        registered_img = cv2.warpAffine(img2, M, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "        registered_img_gray = cv2.cvtColor(registered_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Sobel edge detection\n",
        "        sobel_x = cv2.Sobel(registered_img_gray, cv2.CV_64F, 1, 0, ksize=5)\n",
        "        sobel_y = cv2.Sobel(registered_img_gray, cv2.CV_64F, 0, 1, ksize=5)\n",
        "        sobel_edges = np.sqrt(sobel_x**2 + sobel_y**2)\n",
        "\n",
        "        sobel_binary_edges = (sobel_edges > np.percentile(sobel_edges, 90)).astype(np.uint8)\n",
        "\n",
        "        kernel = np.ones((5, 5), np.uint8)\n",
        "        dilated_edges = cv2.dilate(sobel_binary_edges, kernel, iterations=1)\n",
        "\n",
        "        binary_change_map = dilated_edges > 0\n",
        "\n",
        "        ssim_index = ssim(registered_img_gray, gt_image)\n",
        "        mse_value = mse(registered_img_gray, gt_image)\n",
        "\n",
        "        return ssim_index, mse_value\n",
        "\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/data/train'\n",
        "folder_a_path = os.path.join(base_dir, 'A')\n",
        "folder_b_path = os.path.join(base_dir, 'B')\n",
        "label_path = os.path.join(base_dir, 'label')\n",
        "\n",
        "folder_a_images = os.listdir(folder_a_path)\n",
        "folder_b_images = os.listdir(folder_b_path)\n",
        "label_images = os.listdir(label_path)\n",
        "\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=3)\n",
        "search_params = dict(checks=70)\n",
        "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "ssim_scores = []\n",
        "mse_scores = []\n",
        "\n",
        "# Create pool for multiprocessing\n",
        "pool = Pool()\n",
        "\n",
        "# Iterate through each image pair\n",
        "for ssim_score, mse_score in pool.imap_unordered(process_image_pair, zip(folder_a_images, folder_b_images, label_images)):\n",
        "    if ssim_score is not None:\n",
        "        ssim_scores.append(ssim_score)\n",
        "        mse_scores.append(mse_score)\n",
        "    else:\n",
        "        print(\"Not enough matches for an image pair.\")\n",
        "\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "mean_ssim = np.mean(ssim_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "\n",
        "print(f\"Mean SSIM score: {mean_ssim}\")\n",
        "print(f\"Mean MSE score: {mean_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNObtxnpN9rN",
        "outputId": "d96da0c0-bd3a-4f14-ebab-75b5c20b3a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean SSIM score: 0.6361657128316988\n",
            "Mean MSE score: 5209.105129972737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ORB - PREWITT"
      ],
      "metadata": {
        "id": "E0044S-zY-fP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.metrics import structural_similarity as ssim, mean_squared_error as mse\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Load image with OpenCV\n",
        "def load_image_cv(path):\n",
        "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "\n",
        "def prewitt_operator(img):\n",
        "    kernel_x = np.array([[1, 0, -1],\n",
        "                         [1, 0, -1],\n",
        "                         [1, 0, -1]])\n",
        "\n",
        "    kernel_y = np.array([[1, 1, 1],\n",
        "                         [0, 0, 0],\n",
        "                         [-1, -1, -1]])\n",
        "\n",
        "    prewitt_x = cv2.filter2D(img, -1, kernel_x)\n",
        "    prewitt_y = cv2.filter2D(img, -1, kernel_y)\n",
        "\n",
        "    return np.sqrt(prewitt_x**2 + prewitt_y**2)\n",
        "\n",
        "def process_image_pair(args):\n",
        "    filename_a, filename_b, filename_label = args\n",
        "    img1_path = os.path.join(folder_a_path, filename_a)\n",
        "    img1 = load_image_cv(img1_path)\n",
        "\n",
        "    img2_path = os.path.join(folder_b_path, filename_b)\n",
        "    img2 = load_image_cv(img2_path)\n",
        "\n",
        "    gt_image_path = os.path.join(label_path, filename_label)\n",
        "    gt_image = io.imread(gt_image_path)\n",
        "\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    orb = cv2.ORB_create()\n",
        "\n",
        "    keypoints1, descriptors1 = orb.detectAndCompute(img1_gray, None)\n",
        "    keypoints2, descriptors2 = orb.detectAndCompute(img2_gray, None)\n",
        "\n",
        "    descriptors1_float = descriptors1.astype(np.float32)\n",
        "    descriptors2_float = descriptors2.astype(np.float32)\n",
        "\n",
        "    matches = flann.knnMatch(descriptors1_float, descriptors2_float, k=2)\n",
        "\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.85 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    if len(good_matches) > 10:\n",
        "        points1 = np.zeros((len(good_matches), 2), dtype=np.float32)\n",
        "        points2 = np.zeros_like(points1)\n",
        "\n",
        "        for i, match in enumerate(good_matches):\n",
        "            points1[i, :] = keypoints1[match.queryIdx].pt\n",
        "            points2[i, :] = keypoints2[match.trainIdx].pt\n",
        "\n",
        "        M, mask = cv2.estimateAffinePartial2D(points1, points2, method=cv2.RANSAC)\n",
        "\n",
        "        registered_img = cv2.warpAffine(img2, M, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "        registered_img_gray = cv2.cvtColor(registered_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Prewitt edge detection\n",
        "        prewitt_edges = prewitt_operator(registered_img_gray)\n",
        "        prewitt_binary_edges = (prewitt_edges > np.percentile(prewitt_edges, 90)).astype(np.uint8)\n",
        "\n",
        "        kernel = np.ones((5, 5), np.uint8)\n",
        "        dilated_edges = cv2.dilate(prewitt_binary_edges, kernel, iterations=1)\n",
        "\n",
        "        binary_change_map = dilated_edges > 0\n",
        "\n",
        "        ssim_index = ssim(registered_img_gray, gt_image)\n",
        "        mse_value = mse(registered_img_gray, gt_image)\n",
        "\n",
        "        return ssim_index, mse_value\n",
        "\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/data/train'\n",
        "folder_a_path = os.path.join(base_dir, 'A')\n",
        "folder_b_path = os.path.join(base_dir, 'B')\n",
        "label_path = os.path.join(base_dir, 'label')\n",
        "\n",
        "folder_a_images = os.listdir(folder_a_path)\n",
        "folder_b_images = os.listdir(folder_b_path)\n",
        "label_images = os.listdir(label_path)\n",
        "\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=3)\n",
        "search_params = dict(checks=70)\n",
        "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "ssim_scores = []\n",
        "mse_scores = []\n",
        "\n",
        "# Create pool for multiprocessing\n",
        "pool = Pool()\n",
        "\n",
        "# Iterate through each image pair\n",
        "for ssim_score, mse_score in pool.imap_unordered(process_image_pair, zip(folder_a_images, folder_b_images, label_images)):\n",
        "    if ssim_score is not None:\n",
        "        ssim_scores.append(ssim_score)\n",
        "        mse_scores.append(mse_score)\n",
        "    else:\n",
        "        print(\"Not enough matches for an image pair.\")\n",
        "\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "mean_ssim = np.mean(ssim_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "\n",
        "print(f\"Mean SSIM score: {mean_ssim}\")\n",
        "print(f\"Mean MSE score: {mean_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOqFoDwIN9-c",
        "outputId": "cfb51680-b83b-44fb-fa18-5b17b554274a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean SSIM score: 0.6612250293095355\n",
            "Mean MSE score: 4853.589983243621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ORB - LOG"
      ],
      "metadata": {
        "id": "V54AFaorZBTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.metrics import structural_similarity as ssim, mean_squared_error as mse\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Load image with OpenCV\n",
        "def load_image_cv(path):\n",
        "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "\n",
        "def process_image_pair(args):\n",
        "    filename_a, filename_b, filename_label = args\n",
        "    img1_path = os.path.join(folder_a_path, filename_a)\n",
        "    img1 = load_image_cv(img1_path)\n",
        "\n",
        "    img2_path = os.path.join(folder_b_path, filename_b)\n",
        "    img2 = load_image_cv(img2_path)\n",
        "\n",
        "    gt_image_path = os.path.join(label_path, filename_label)\n",
        "    gt_image = io.imread(gt_image_path)\n",
        "\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    orb = cv2.ORB_create()\n",
        "\n",
        "    keypoints1, descriptors1 = orb.detectAndCompute(img1_gray, None)\n",
        "    keypoints2, descriptors2 = orb.detectAndCompute(img2_gray, None)\n",
        "\n",
        "    descriptors1_float = descriptors1.astype(np.float32)\n",
        "    descriptors2_float = descriptors2.astype(np.float32)\n",
        "\n",
        "    matches = flann.knnMatch(descriptors1_float, descriptors2_float, k=2)\n",
        "\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.85 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    if len(good_matches) > 10:\n",
        "        points1 = np.zeros((len(good_matches), 2), dtype=np.float32)\n",
        "        points2 = np.zeros_like(points1)\n",
        "\n",
        "        for i, match in enumerate(good_matches):\n",
        "            points1[i, :] = keypoints1[match.queryIdx].pt\n",
        "            points2[i, :] = keypoints2[match.trainIdx].pt\n",
        "\n",
        "        M, mask = cv2.estimateAffinePartial2D(points1, points2, method=cv2.RANSAC)\n",
        "\n",
        "        registered_img = cv2.warpAffine(img2, M, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "        registered_img_gray = cv2.cvtColor(registered_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply Gaussian blur\n",
        "        blurred_img = cv2.GaussianBlur(registered_img_gray, (5, 5), 0)\n",
        "\n",
        "        # Apply Laplacian of Gaussian (LoG) operator\n",
        "        log_edges = cv2.Laplacian(blurred_img, cv2.CV_64F)\n",
        "\n",
        "        log_binary_edges = (log_edges > np.percentile(log_edges, 90)).astype(np.uint8)\n",
        "\n",
        "        kernel = np.ones((5, 5), np.uint8)\n",
        "        dilated_edges = cv2.dilate(log_binary_edges, kernel, iterations=1)\n",
        "\n",
        "        binary_change_map = dilated_edges > 0\n",
        "\n",
        "        ssim_index = ssim(registered_img_gray, gt_image)\n",
        "        mse_value = mse(registered_img_gray, gt_image)\n",
        "\n",
        "        return ssim_index, mse_value\n",
        "\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/data/train'\n",
        "folder_a_path = os.path.join(base_dir, 'A')\n",
        "folder_b_path = os.path.join(base_dir, 'B')\n",
        "label_path = os.path.join(base_dir, 'label')\n",
        "\n",
        "folder_a_images = os.listdir(folder_a_path)\n",
        "folder_b_images = os.listdir(folder_b_path)\n",
        "label_images = os.listdir(label_path)\n",
        "\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=3)\n",
        "search_params = dict(checks=70)\n",
        "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "ssim_scores = []\n",
        "mse_scores = []\n",
        "\n",
        "# Create pool for multiprocessing\n",
        "pool = Pool()\n",
        "\n",
        "# Iterate through each image pair\n",
        "for ssim_score, mse_score in pool.imap_unordered(process_image_pair, zip(folder_a_images, folder_b_images, label_images)):\n",
        "    if ssim_score is not None:\n",
        "        ssim_scores.append(ssim_score)\n",
        "        mse_scores.append(mse_score)\n",
        "    else:\n",
        "        print(\"Not enough matches for an image pair.\")\n",
        "\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "mean_ssim = np.mean(ssim_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "\n",
        "print(f\"Mean SSIM score: {mean_ssim}\")\n",
        "print(f\"Mean MSE score: {mean_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG6Cp4RaN-Ib",
        "outputId": "a131c78f-bc2a-4ecd-c77b-6b87eef1f22c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean SSIM score: 0.6424586983995815\n",
            "Mean MSE score: 5087.835956637779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ORB - SCHAAR"
      ],
      "metadata": {
        "id": "HI4L4kw1ZEzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.metrics import structural_similarity as ssim, mean_squared_error as mse\n",
        "import matplotlib.pyplot as plt\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Load image with OpenCV\n",
        "def load_image_cv(path):\n",
        "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "\n",
        "def process_image_pair(args):\n",
        "    filename_a, filename_b, filename_label = args\n",
        "    img1_path = os.path.join(folder_a_path, filename_a)\n",
        "    img1 = load_image_cv(img1_path)\n",
        "\n",
        "    img2_path = os.path.join(folder_b_path, filename_b)\n",
        "    img2 = load_image_cv(img2_path)\n",
        "\n",
        "    gt_image_path = os.path.join(label_path, filename_label)\n",
        "    gt_image = io.imread(gt_image_path)\n",
        "\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    orb = cv2.ORB_create()\n",
        "\n",
        "    keypoints1, descriptors1 = orb.detectAndCompute(img1_gray, None)\n",
        "    keypoints2, descriptors2 = orb.detectAndCompute(img2_gray, None)\n",
        "\n",
        "    descriptors1_float = descriptors1.astype(np.float32)\n",
        "    descriptors2_float = descriptors2.astype(np.float32)\n",
        "\n",
        "    matches = flann.knnMatch(descriptors1_float, descriptors2_float, k=2)\n",
        "\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.85 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    if len(good_matches) > 10:\n",
        "        points1 = np.zeros((len(good_matches), 2), dtype=np.float32)\n",
        "        points2 = np.zeros_like(points1)\n",
        "\n",
        "        for i, match in enumerate(good_matches):\n",
        "            points1[i, :] = keypoints1[match.queryIdx].pt\n",
        "            points2[i, :] = keypoints2[match.trainIdx].pt\n",
        "\n",
        "        M, mask = cv2.estimateAffinePartial2D(points1, points2, method=cv2.RANSAC)\n",
        "\n",
        "        registered_img = cv2.warpAffine(img2, M, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "        registered_img_gray = cv2.cvtColor(registered_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply Scharr operator for edge detection\n",
        "        scharr_x = cv2.Scharr(registered_img_gray, cv2.CV_64F, 1, 0)\n",
        "        scharr_y = cv2.Scharr(registered_img_gray, cv2.CV_64F, 0, 1)\n",
        "        scharr_edges = np.sqrt(scharr_x**2 + scharr_y**2)\n",
        "\n",
        "        scharr_binary_edges = (scharr_edges > np.percentile(scharr_edges, 90)).astype(np.uint8)\n",
        "\n",
        "        kernel = np.ones((5, 5), np.uint8)\n",
        "        dilated_edges = cv2.dilate(scharr_binary_edges, kernel, iterations=1)\n",
        "\n",
        "        binary_change_map = dilated_edges > 0\n",
        "\n",
        "        ssim_index = ssim(registered_img_gray, gt_image)\n",
        "        mse_value = mse(registered_img_gray, gt_image)\n",
        "\n",
        "        return ssim_index, mse_value\n",
        "\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/data/train'\n",
        "folder_a_path = os.path.join(base_dir, 'A')\n",
        "folder_b_path = os.path.join(base_dir, 'B')\n",
        "label_path = os.path.join(base_dir, 'label')\n",
        "\n",
        "folder_a_images = os.listdir(folder_a_path)\n",
        "folder_b_images = os.listdir(folder_b_path)\n",
        "label_images = os.listdir(label_path)\n",
        "\n",
        "FLANN_INDEX_KDTREE = 1\n",
        "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=3)\n",
        "search_params = dict(checks=70)\n",
        "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "ssim_scores = []\n",
        "mse_scores = []\n",
        "\n",
        "# Create pool for multiprocessing\n",
        "pool = Pool()\n",
        "\n",
        "# Iterate through each image pair\n",
        "for ssim_score, mse_score in pool.imap_unordered(process_image_pair, zip(folder_a_images, folder_b_images, label_images)):\n",
        "    if ssim_score is not None:\n",
        "        ssim_scores.append(ssim_score)\n",
        "        mse_scores.append(mse_score)\n",
        "    else:\n",
        "        print(\"Not enough matches for an image pair.\")\n",
        "\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "mean_ssim = np.mean(ssim_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "\n",
        "print(f\"Mean SSIM score: {mean_ssim}\")\n",
        "print(f\"Mean MSE score: {mean_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YypERUDcN_xb",
        "outputId": "86717b6f-5823-465f-a07e-659af244db98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean SSIM score: 0.6473816073386206\n",
            "Mean MSE score: 5022.703651093901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.metrics import structural_similarity as ssim, mean_squared_error as mse\n",
        "\n",
        "# Load image with OpenCV\n",
        "def load_image_cv(path):\n",
        "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "\n",
        "def process_image_pair(filename_a, filename_b, filename_label):\n",
        "    img1_path = os.path.join(folder_a_path, filename_a)\n",
        "    img1 = load_image_cv(img1_path)\n",
        "\n",
        "    img2_path = os.path.join(folder_b_path, filename_b)\n",
        "    img2 = load_image_cv(img2_path)\n",
        "\n",
        "    gt_image_path = os.path.join(label_path, filename_label)\n",
        "    gt_image = io.imread(gt_image_path)\n",
        "\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Create SIFT detector\n",
        "    sift = cv2.SIFT_create()\n",
        "\n",
        "    # Detect keypoints and compute descriptors\n",
        "    keypoints1, descriptors1 = sift.detectAndCompute(img1_gray, None)\n",
        "    keypoints2, descriptors2 = sift.detectAndCompute(img2_gray, None)\n",
        "\n",
        "    # FLANN parameters\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=3)\n",
        "    search_params = dict(checks=70)\n",
        "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "    # Match descriptors using FLANN\n",
        "    matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
        "\n",
        "    # Ratio test to find good matches\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.75 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    if len(good_matches) > 10:\n",
        "        # Extract keypoints for good matches\n",
        "        points1 = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "        points2 = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "\n",
        "        # Find homography using RANSAC\n",
        "        M, mask = cv2.findHomography(points2, points1, cv2.RANSAC, 5.0)\n",
        "\n",
        "        # Warp image2 to image1 using homography\n",
        "        registered_img = cv2.warpPerspective(img2, M, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "        # Convert registered image to grayscale\n",
        "        registered_img_gray = cv2.cvtColor(registered_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply edge detection using Canny\n",
        "        edges_registered = cv2.Canny(registered_img_gray, 200, 585)\n",
        "\n",
        "        # Compute SSIM and MSE\n",
        "        ssim_index = ssim(edges_registered, gt_image)\n",
        "        mse_value = mse(edges_registered, gt_image)\n",
        "\n",
        "        return ssim_index, mse_value\n",
        "\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/data/train'\n",
        "folder_a_path = os.path.join(base_dir, 'A')\n",
        "folder_b_path = os.path.join(base_dir, 'B')\n",
        "label_path = os.path.join(base_dir, 'label')\n",
        "\n",
        "folder_a_images = os.listdir(folder_a_path)\n",
        "folder_b_images = os.listdir(folder_b_path)\n",
        "label_images = os.listdir(label_path)\n",
        "\n",
        "ssim_scores = []\n",
        "mse_scores = []\n",
        "\n",
        "# Iterate through each image pair\n",
        "for filename_a, filename_b, filename_label in zip(folder_a_images, folder_b_images, label_images):\n",
        "    ssim_score, mse_score = process_image_pair(filename_a, filename_b, filename_label)\n",
        "    if ssim_score is not None:\n",
        "        ssim_scores.append(ssim_score)\n",
        "        mse_scores.append(mse_score)\n",
        "    else:\n",
        "        print(\"Not enough matches for an image pair.\")\n",
        "\n",
        "mean_ssim = np.mean(ssim_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "\n",
        "print(f\"Mean SSIM score: {mean_ssim}\")\n",
        "print(f\"Mean MSE score: {mean_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYP77Zd_S8FU",
        "outputId": "1e4302d4-b168-4071-ee86-6cafbb379534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Mean SSIM score: 0.8750486043485063\n",
            "Mean MSE score: 3601.588294626376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.metrics import structural_similarity as ssim, mean_squared_error as mse\n",
        "\n",
        "# Load image with OpenCV\n",
        "def load_image_cv(path):\n",
        "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "\n",
        "def process_image_pair(filename_a, filename_b, filename_label):\n",
        "    img1_path = os.path.join(folder_a_path, filename_a)\n",
        "    img1 = load_image_cv(img1_path)\n",
        "\n",
        "    img2_path = os.path.join(folder_b_path, filename_b)\n",
        "    img2 = load_image_cv(img2_path)\n",
        "\n",
        "    gt_image_path = os.path.join(label_path, filename_label)\n",
        "    gt_image = io.imread(gt_image_path)\n",
        "\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Create SIFT detector\n",
        "    sift = cv2.SIFT_create()\n",
        "\n",
        "    # Detect keypoints and compute descriptors\n",
        "    keypoints1, descriptors1 = sift.detectAndCompute(img1_gray, None)\n",
        "    keypoints2, descriptors2 = sift.detectAndCompute(img2_gray, None)\n",
        "\n",
        "    # FLANN parameters\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=7)\n",
        "    search_params = dict(checks=40)\n",
        "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "    # Match descriptors using FLANN\n",
        "    matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
        "\n",
        "    # Ratio test to find good matches\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.80 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    if len(good_matches) > 10:\n",
        "        # Extract keypoints for good matches\n",
        "        points1 = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "        points2 = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "\n",
        "        # Find homography using RANSAC\n",
        "        M, mask = cv2.findHomography(points2, points1, cv2.RANSAC, 5.0)\n",
        "\n",
        "        # Warp image2 to image1 using homography\n",
        "        registered_img = cv2.warpPerspective(img2, M, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "        # Convert registered image to grayscale\n",
        "        registered_img_gray = cv2.cvtColor(registered_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply edge detection using Sobel\n",
        "        sobel_x = cv2.Sobel(registered_img_gray, cv2.CV_64F, 1, 0, ksize=7)\n",
        "        sobel_y = cv2.Sobel(registered_img_gray, cv2.CV_64F, 0, 1, ksize=7)\n",
        "        edges_registered = np.sqrt(sobel_x**2 + sobel_y**2)\n",
        "\n",
        "        # Convert edges_registered to the same data type as gt_image\n",
        "        edges_registered = edges_registered.astype(gt_image.dtype)\n",
        "\n",
        "        # Compute SSIM and MSE\n",
        "        ssim_index = ssim(edges_registered, gt_image)\n",
        "        mse_value = mse(edges_registered, gt_image)\n",
        "\n",
        "        return ssim_index, mse_value\n",
        "\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/data/train'\n",
        "folder_a_path = os.path.join(base_dir, 'A')\n",
        "folder_b_path = os.path.join(base_dir, 'B')\n",
        "label_path = os.path.join(base_dir, 'label')\n",
        "\n",
        "folder_a_images = os.listdir(folder_a_path)\n",
        "folder_b_images = os.listdir(folder_b_path)\n",
        "label_images = os.listdir(label_path)\n",
        "\n",
        "ssim_scores = []\n",
        "mse_scores = []\n",
        "\n",
        "# Iterate through each image pair\n",
        "for filename_a, filename_b, filename_label in zip(folder_a_images, folder_b_images, label_images):\n",
        "    ssim_score, mse_score = process_image_pair(filename_a, filename_b, filename_label)\n",
        "    if ssim_score is not None:\n",
        "        ssim_scores.append(ssim_score)\n",
        "        mse_scores.append(mse_score)\n",
        "    else:\n",
        "        print(\"Not enough matches for an image pair.\")\n",
        "\n",
        "mean_ssim = np.mean(ssim_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "\n",
        "print(f\"Mean SSIM score: {mean_ssim}\")\n",
        "print(f\"Mean MSE score: {mean_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9Cqr7lbx2_5",
        "outputId": "a1b76126-285f-47a6-a23c-37f7a0d1ca24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean SSIM score: 0.29712164975574495\n",
            "Mean MSE score: 15220.920973070552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.metrics import structural_similarity as ssim, mean_squared_error as mse\n",
        "\n",
        "# Load image with OpenCV\n",
        "def load_image_cv(path):\n",
        "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "\n",
        "def process_image_pair(filename_a, filename_b, filename_label):\n",
        "    img1_path = os.path.join(folder_a_path, filename_a)\n",
        "    img1 = load_image_cv(img1_path)\n",
        "\n",
        "    img2_path = os.path.join(folder_b_path, filename_b)\n",
        "    img2 = load_image_cv(img2_path)\n",
        "\n",
        "    gt_image_path = os.path.join(label_path, filename_label)\n",
        "    gt_image = io.imread(gt_image_path)\n",
        "\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Create SIFT detector\n",
        "    sift = cv2.SIFT_create()\n",
        "\n",
        "    # Detect keypoints and compute descriptors\n",
        "    keypoints1, descriptors1 = sift.detectAndCompute(img1_gray, None)\n",
        "    keypoints2, descriptors2 = sift.detectAndCompute(img2_gray, None)\n",
        "\n",
        "    # FLANN parameters\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=3)\n",
        "    search_params = dict(checks=70)\n",
        "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "    # Match descriptors using FLANN\n",
        "    matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
        "\n",
        "    # Ratio test to find good matches\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.75 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    if len(good_matches) > 10:\n",
        "        # Extract keypoints for good matches\n",
        "        points1 = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "        points2 = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "\n",
        "        # Find homography using RANSAC\n",
        "        M, mask = cv2.findHomography(points2, points1, cv2.RANSAC, 5.0)\n",
        "\n",
        "        # Warp image2 to image1 using homography\n",
        "        registered_img = cv2.warpPerspective(img2, M, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "        # Convert registered image to grayscale\n",
        "        registered_img_gray = cv2.cvtColor(registered_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply edge detection using Prewitt\n",
        "        kernel_x = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]])\n",
        "        kernel_y = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]])\n",
        "        sobel_x = cv2.filter2D(registered_img_gray, -1, kernel_x)\n",
        "        sobel_y = cv2.filter2D(registered_img_gray, -1, kernel_y)\n",
        "        edges_registered = np.sqrt(sobel_x**2 + sobel_y**2)\n",
        "\n",
        "        # Convert edges_registered to the same data type as gt_image\n",
        "        edges_registered = edges_registered.astype(gt_image.dtype)\n",
        "\n",
        "        # Compute SSIM and MSE\n",
        "        ssim_index = ssim(edges_registered, gt_image)\n",
        "        mse_value = mse(edges_registered, gt_image)\n",
        "\n",
        "        return ssim_index, mse_value\n",
        "\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/data/train'\n",
        "folder_a_path = os.path.join(base_dir, 'A')\n",
        "folder_b_path = os.path.join(base_dir, 'B')\n",
        "label_path = os.path.join(base_dir, 'label')\n",
        "\n",
        "folder_a_images = os.listdir(folder_a_path)\n",
        "folder_b_images = os.listdir(folder_b_path)\n",
        "label_images = os.listdir(label_path)\n",
        "\n",
        "ssim_scores = []\n",
        "mse_scores = []\n",
        "\n",
        "# Iterate through each image pair\n",
        "for filename_a, filename_b, filename_label in zip(folder_a_images, folder_b_images, label_images):\n",
        "    ssim_score, mse_score = process_image_pair(filename_a, filename_b, filename_label)\n",
        "    if ssim_score is not None:\n",
        "        ssim_scores.append(ssim_score)\n",
        "        mse_scores.append(mse_score)\n",
        "    else:\n",
        "        print(\"Not enough matches for an image pair.\")\n",
        "\n",
        "mean_ssim = np.mean(ssim_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "\n",
        "print(f\"Mean SSIM score: {mean_ssim}\")\n",
        "print(f\"Mean MSE score: {mean_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9wv5NAI7azb",
        "outputId": "cc904685-41cd-430f-a5b2-724273e614ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Mean SSIM score: 0.4993893572244242\n",
            "Mean MSE score: 2937.5731402207293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.metrics import structural_similarity as ssim, mean_squared_error as mse\n",
        "\n",
        "# Load image with OpenCV\n",
        "def load_image_cv(path):\n",
        "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "\n",
        "def process_image_pair(filename_a, filename_b, filename_label):\n",
        "    img1_path = os.path.join(folder_a_path, filename_a)\n",
        "    img1 = load_image_cv(img1_path)\n",
        "\n",
        "    img2_path = os.path.join(folder_b_path, filename_b)\n",
        "    img2 = load_image_cv(img2_path)\n",
        "\n",
        "    gt_image_path = os.path.join(label_path, filename_label)\n",
        "    gt_image = io.imread(gt_image_path)\n",
        "\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Create SIFT detector\n",
        "    sift = cv2.SIFT_create()\n",
        "\n",
        "    # Detect keypoints and compute descriptors\n",
        "    keypoints1, descriptors1 = sift.detectAndCompute(img1_gray, None)\n",
        "    keypoints2, descriptors2 = sift.detectAndCompute(img2_gray, None)\n",
        "\n",
        "    # FLANN parameters\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=3)\n",
        "    search_params = dict(checks=70)\n",
        "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "    # Match descriptors using FLANN\n",
        "    matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
        "\n",
        "    # Ratio test to find good matches\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.75 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    if len(good_matches) > 10:\n",
        "        # Extract keypoints for good matches\n",
        "        points1 = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "        points2 = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "\n",
        "        # Find homography using RANSAC\n",
        "        M, mask = cv2.findHomography(points2, points1, cv2.RANSAC, 5.0)\n",
        "\n",
        "        # Warp image2 to image1 using homography\n",
        "        registered_img = cv2.warpPerspective(img2, M, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "        # Convert registered image to grayscale\n",
        "        registered_img_gray = cv2.cvtColor(registered_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply Gaussian blur\n",
        "        registered_img_blur = cv2.GaussianBlur(registered_img_gray, (3, 3), 0)\n",
        "\n",
        "        # Apply Laplacian of Gaussian (LOG)\n",
        "        edges_registered = cv2.Laplacian(registered_img_blur, cv2.CV_64F)\n",
        "\n",
        "        # Convert edges_registered to the same data type as gt_image\n",
        "        edges_registered = edges_registered.astype(gt_image.dtype)\n",
        "\n",
        "        # Compute SSIM and MSE\n",
        "        ssim_index = ssim(edges_registered, gt_image)\n",
        "        mse_value = mse(edges_registered, gt_image)\n",
        "\n",
        "        return ssim_index, mse_value\n",
        "\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/data/train'\n",
        "folder_a_path = os.path.join(base_dir, 'A')\n",
        "folder_b_path = os.path.join(base_dir, 'B')\n",
        "label_path = os.path.join(base_dir, 'label')\n",
        "\n",
        "folder_a_images = os.listdir(folder_a_path)\n",
        "folder_b_images = os.listdir(folder_b_path)\n",
        "label_images = os.listdir(label_path)\n",
        "\n",
        "ssim_scores = []\n",
        "mse_scores = []\n",
        "\n",
        "# Iterate through each image pair\n",
        "for filename_a, filename_b, filename_label in zip(folder_a_images, folder_b_images, label_images):\n",
        "    ssim_score, mse_score = process_image_pair(filename_a, filename_b, filename_label)\n",
        "    if ssim_score is not None:\n",
        "        ssim_scores.append(ssim_score)\n",
        "        mse_scores.append(mse_score)\n",
        "    else:\n",
        "        print(\"Not enough matches for an image pair.\")\n",
        "\n",
        "mean_ssim = np.mean(ssim_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "\n",
        "print(f\"Mean SSIM score: {mean_ssim}\")\n",
        "print(f\"Mean MSE score: {mean_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8BgINf97a76",
        "outputId": "94768039-b6f1-4fd9-fbda-3e035fb38cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Not enough matches for an image pair.\n",
            "Mean SSIM score: 0.29569466300430763\n",
            "Mean MSE score: 18359.52167043294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from skimage.metrics import structural_similarity as ssim, mean_squared_error as mse\n",
        "\n",
        "# Load image with OpenCV\n",
        "def load_image_cv(path):\n",
        "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "\n",
        "def process_image_pair(filename_a, filename_b, filename_label):\n",
        "    img1_path = os.path.join(folder_a_path, filename_a)\n",
        "    img1 = load_image_cv(img1_path)\n",
        "\n",
        "    img2_path = os.path.join(folder_b_path, filename_b)\n",
        "    img2 = load_image_cv(img2_path)\n",
        "\n",
        "    gt_image_path = os.path.join(label_path, filename_label)\n",
        "    gt_image = io.imread(gt_image_path)\n",
        "\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Create SIFT detector\n",
        "    sift = cv2.SIFT_create()\n",
        "\n",
        "    # Detect keypoints and compute descriptors\n",
        "    keypoints1, descriptors1 = sift.detectAndCompute(img1_gray, None)\n",
        "    keypoints2, descriptors2 = sift.detectAndCompute(img2_gray, None)\n",
        "\n",
        "    # FLANN parameters\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=10)\n",
        "    search_params = dict(checks=100)\n",
        "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "    # Match descriptors using FLANN\n",
        "    matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
        "\n",
        "    # Ratio test to find good matches\n",
        "    good_matches = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.90 * n.distance:\n",
        "            good_matches.append(m)\n",
        "\n",
        "    if len(good_matches) > 10:\n",
        "        # Extract keypoints for good matches\n",
        "        points1 = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "        points2 = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "\n",
        "        # Find homography using RANSAC\n",
        "        M, mask = cv2.findHomography(points2, points1, cv2.RANSAC, 5.0)\n",
        "\n",
        "        # Warp image2 to image1 using homography\n",
        "        registered_img = cv2.warpPerspective(img2, M, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "        # Convert registered image to grayscale\n",
        "        registered_img_gray = cv2.cvtColor(registered_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply Scharr edge detection\n",
        "        edges_registered = cv2.Scharr(registered_img_gray, -1, 1, 0)\n",
        "\n",
        "        # Convert edges_registered to the same data type as gt_image\n",
        "        edges_registered = edges_registered.astype(gt_image.dtype)\n",
        "\n",
        "        # Compute SSIM and MSE\n",
        "        ssim_index = ssim(edges_registered, gt_image)\n",
        "        mse_value = mse(edges_registered, gt_image)\n",
        "\n",
        "        return ssim_index, mse_value\n",
        "\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/data/train'\n",
        "folder_a_path = os.path.join(base_dir, 'A')\n",
        "folder_b_path = os.path.join(base_dir, 'B')\n",
        "label_path = os.path.join(base_dir, 'label')\n",
        "\n",
        "folder_a_images = os.listdir(folder_a_path)\n",
        "folder_b_images = os.listdir(folder_b_path)\n",
        "label_images = os.listdir(label_path)\n",
        "\n",
        "ssim_scores = []\n",
        "mse_scores = []\n",
        "\n",
        "# Iterate through each image pair\n",
        "for filename_a, filename_b, filename_label in zip(folder_a_images, folder_b_images, label_images):\n",
        "    ssim_score, mse_score = process_image_pair(filename_a, filename_b, filename_label)\n",
        "    if ssim_score is not None:\n",
        "        ssim_scores.append(ssim_score)\n",
        "        mse_scores.append(mse_score)\n",
        "    else:\n",
        "        print(\"Not enough matches for an image pair.\")\n",
        "\n",
        "mean_ssim = np.mean(ssim_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "\n",
        "print(f\"Mean SSIM score: {mean_ssim}\")\n",
        "print(f\"Mean MSE score: {mean_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFOn_kXw7bCu",
        "outputId": "ba4e566d-ac7a-422a-d569-5ecdc2fe472f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean SSIM score: 0.41610727504900197\n",
            "Mean MSE score: 6733.718012053243\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}